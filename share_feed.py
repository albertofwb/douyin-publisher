#!/usr/bin/env python3
"""
ä¸€é”®åˆ·æ¨åˆ†äº«åˆ°æŠ–éŸ³

ç”¨æ³•:
  share_feed                    # æŠ“å–æ¨ç‰¹ â†’ é€‰æ‹©å†…å®¹ â†’ ç”Ÿæˆè§†é¢‘ â†’ å‘å¸ƒ
  share_feed --dry-run          # åªç”Ÿæˆä¸å‘å¸ƒ
  share_feed --text "å†…å®¹"      # ç›´æ¥æŒ‡å®šå†…å®¹
"""

import argparse
import subprocess
import sys
import tempfile
from pathlib import Path

SCRIPT_DIR = Path(__file__).parent.resolve()


def fetch_feed() -> str | None:
    """è°ƒç”¨ twfeed æŠ“å–æ¨ç‰¹æ—¶é—´çº¿"""
    print("ğŸ“¡ æŠ“å–æ¨ç‰¹æ—¶é—´çº¿...")
    result = subprocess.run(
        ["twfeed", "--height", "4000"],
        capture_output=True,
        text=True,
        timeout=120
    )
    if result.returncode != 0:
        print(f"âŒ æŠ“å–å¤±è´¥: {result.stderr}", file=sys.stderr)
        return None
    return result.stdout.strip()


def parse_tweets(ocr_text: str) -> list[dict]:
    """ä» OCR æ–‡æœ¬è§£ææ¨æ–‡"""
    tweets = []
    lines = ocr_text.split('\n')
    
    current_tweet = {"author": "", "content": []}
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # æ£€æµ‹ç”¨æˆ·åæ¨¡å¼ (xxx @xxx Â· æ—¶é—´)
        if '@' in line and ('Â·' in line or 'â€¢' in line or 'h' in line or 'm' in line):
            # ä¿å­˜ä¸Šä¸€æ¡æ¨æ–‡
            if current_tweet["content"]:
                tweets.append(current_tweet)
            current_tweet = {"author": line, "content": []}
        elif current_tweet["author"]:
            # è·³è¿‡å¹¿å‘Šå’Œæ— å…³å†…å®¹
            skip_keywords = ['Ad', 'å¹¿å‘Š', 'Promoted', 'Subscribe', 'è®¢é˜…', 'å…³æ³¨', 'Follow']
            if not any(kw in line for kw in skip_keywords):
                current_tweet["content"].append(line)
    
    # ä¿å­˜æœ€åä¸€æ¡
    if current_tweet["content"]:
        tweets.append(current_tweet)
    
    return tweets


def sanitize_for_douyin(text: str) -> str:
    """å»é™¤æ•æ„Ÿè¯"""
    import re
    replacements = {
        r'æ¨ç‰¹': 'æŸå¹³å°',
        r'Twitter': 'æŸå¹³å°',
        r'X\.com': 'æŸå¹³å°',
        r'tweet': 'å¸–å­',
        r'æ¨æ–‡': 'å¸–å­',
        r'@[\w]+': '',  # ç§»é™¤ @ç”¨æˆ·å
    }
    for pattern, replacement in replacements.items():
        text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
    return text.strip()


def select_tweets(tweets: list[dict]) -> list[dict]:
    """äº¤äº’å¼é€‰æ‹©è¦åˆ†äº«çš„æ¨æ–‡"""
    if not tweets:
        return []
    
    print(f"\nğŸ“‹ æ‰¾åˆ° {len(tweets)} æ¡æ¨æ–‡ï¼Œé€‰æ‹©è¦åˆ†äº«çš„ï¼š\n")
    
    for i, tweet in enumerate(tweets[:10], 1):  # æœ€å¤šæ˜¾ç¤º 10 æ¡
        content = ' '.join(tweet['content'])[:80]
        print(f"  [{i}] {content}...")
    
    print(f"\n  [a] å…¨é€‰å‰5æ¡")
    print(f"  [q] é€€å‡º")
    
    try:
        choice = input("\né€‰æ‹© (æ•°å­—/a/q): ").strip().lower()
    except (EOFError, KeyboardInterrupt):
        return []
    
    if choice == 'q':
        return []
    elif choice == 'a':
        return tweets[:5]
    else:
        try:
            indices = [int(x.strip()) - 1 for x in choice.split(',')]
            return [tweets[i] for i in indices if 0 <= i < len(tweets)]
        except:
            return []


def generate_script(tweets: list[dict]) -> tuple[str, str]:
    """ç”ŸæˆæŠ–éŸ³è§†é¢‘çš„æ ‡é¢˜å’Œæ–‡æ¡ˆ"""
    if not tweets:
        return "", ""
    
    # æ ‡é¢˜
    title = "ä»Šæ—¥ç½‘ç»œè§é—»"
    
    # æ–‡æ¡ˆï¼ˆTTS å†…å®¹ï¼‰
    lines = ["å¤§å®¶å¥½ï¼Œä»Šå¤©åœ¨ç½‘ä¸Šçœ‹åˆ°å‡ ä¸ªæœ‰æ„æ€çš„äº‹æƒ…ï¼Œåˆ†äº«ç»™å¤§å®¶ã€‚"]
    
    for i, tweet in enumerate(tweets, 1):
        content = sanitize_for_douyin(' '.join(tweet['content']))
        if content:
            lines.append(f"ç¬¬{i}ä¸ªï¼Œ{content}")
    
    lines.append("å¥½äº†ï¼Œä»Šå¤©å°±åˆ†äº«åˆ°è¿™é‡Œï¼Œè§‰å¾—æœ‰æ„æ€çš„è¯ç‚¹ä¸ªèµå§ï¼")
    
    script = '\n'.join(lines)
    return title, script


def main():
    parser = argparse.ArgumentParser(description="ä¸€é”®åˆ·æ¨åˆ†äº«åˆ°æŠ–éŸ³")
    parser.add_argument("--text", "-t", help="ç›´æ¥æŒ‡å®šåˆ†äº«å†…å®¹")
    parser.add_argument("--title", default="ä»Šæ—¥è§é—»", help="è§†é¢‘æ ‡é¢˜")
    parser.add_argument("--dry-run", action="store_true", help="åªç”Ÿæˆä¸å‘å¸ƒ")
    parser.add_argument("--hotspot", help="å…³è”çƒ­ç‚¹")
    parser.add_argument("--no-fetch", action="store_true", help="ä¸æŠ“å–ï¼Œä½¿ç”¨ä¸Šæ¬¡çš„å†…å®¹")
    args = parser.parse_args()
    
    if args.text:
        # ç›´æ¥ä½¿ç”¨æŒ‡å®šå†…å®¹
        title = args.title
        script = sanitize_for_douyin(args.text)
    else:
        # æŠ“å–å¹¶é€‰æ‹©
        ocr_text = fetch_feed()
        if not ocr_text:
            sys.exit(1)
        
        tweets = parse_tweets(ocr_text)
        if not tweets:
            print("âŒ æœªè§£æåˆ°æœ‰æ•ˆæ¨æ–‡")
            sys.exit(1)
        
        selected = select_tweets(tweets)
        if not selected:
            print("ğŸ‘‹ å·²å–æ¶ˆ")
            sys.exit(0)
        
        title, script = generate_script(selected)
    
    print(f"\nğŸ“ æ ‡é¢˜: {title}")
    print(f"ğŸ“ æ–‡æ¡ˆ:\n{script[:200]}...")
    
    # ç¡®è®¤
    try:
        confirm = input("\nç¡®è®¤ç”Ÿæˆè§†é¢‘? [Y/n]: ").strip().lower()
    except (EOFError, KeyboardInterrupt):
        confirm = 'n'
    
    if confirm == 'n':
        print("ğŸ‘‹ å·²å–æ¶ˆ")
        sys.exit(0)
    
    # è°ƒç”¨ feed_share ç”Ÿæˆå¹¶å‘å¸ƒ
    cmd = ["python3", str(SCRIPT_DIR / "feed_share.py"), title, script]
    if not args.dry_run:
        cmd.append("--post")
    if args.hotspot:
        cmd.extend(["--hotspot", args.hotspot])
    
    print("\n" + "="*50)
    subprocess.run(cmd)


if __name__ == "__main__":
    main()
